[INFO] Scanning for projects...
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building entity 1.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- exec-maven-plugin:3.1.0:java (default-cli) @ entity ---
Error loading address data:
java.io.FileNotFoundException: exchanges.csv (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at java.io.FileReader.<init>(FileReader.java:58)
	at entity.deposit.loadAddressData(deposit.java:85)
	at entity.deposit.<clinit>(deposit.java:21)
	at sun.misc.Unsafe.ensureClassInitialized(Native Method)
	at java.lang.invoke.DirectMethodHandle$EnsureInitialized.computeValue(DirectMethodHandle.java:330)
	at java.lang.invoke.DirectMethodHandle$EnsureInitialized.computeValue(DirectMethodHandle.java:327)
	at java.lang.ClassValue.getFromHashMap(ClassValue.java:227)
	at java.lang.ClassValue.getFromBackup(ClassValue.java:209)
	at java.lang.ClassValue.get(ClassValue.java:115)
	at java.lang.invoke.DirectMethodHandle.checkInitialized(DirectMethodHandle.java:351)
	at java.lang.invoke.DirectMethodHandle.ensureInitialized(DirectMethodHandle.java:341)
	at java.lang.invoke.DirectMethodHandle.internalMemberNameEnsureInit(DirectMethodHandle.java:291)
	at org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:279)
	at java.lang.Thread.run(Thread.java:748)
Error loading address data:
java.io.FileNotFoundException: miners_eth.txt (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at java.io.FileReader.<init>(FileReader.java:58)
	at entity.deposit.loadAddressData(deposit.java:85)
	at entity.deposit.<clinit>(deposit.java:22)
	at sun.misc.Unsafe.ensureClassInitialized(Native Method)
	at java.lang.invoke.DirectMethodHandle$EnsureInitialized.computeValue(DirectMethodHandle.java:330)
	at java.lang.invoke.DirectMethodHandle$EnsureInitialized.computeValue(DirectMethodHandle.java:327)
	at java.lang.ClassValue.getFromHashMap(ClassValue.java:227)
	at java.lang.ClassValue.getFromBackup(ClassValue.java:209)
	at java.lang.ClassValue.get(ClassValue.java:115)
	at java.lang.invoke.DirectMethodHandle.checkInitialized(DirectMethodHandle.java:351)
	at java.lang.invoke.DirectMethodHandle.ensureInitialized(DirectMethodHandle.java:341)
	at java.lang.invoke.DirectMethodHandle.internalMemberNameEnsureInit(DirectMethodHandle.java:291)
	at org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:279)
	at java.lang.Thread.run(Thread.java:748)
当前时间戳（秒）: 1747622484
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/public/home/blockchain_2/slave2/.m2/repository/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/public/home/blockchain_2/slave2/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.17.1/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Reload4jLoggerFactory]
log4j:WARN No appenders could be found for logger (org.apache.commons.beanutils.converters.BooleanConverter).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
Loaded 10 addresses from file
Processing address: 930df1513a914455c3f07e320de6e3170078e55f
弱连通分量已写入文件: Randomadd_deposit/930df1513a914455c3f07e320de6e3170078e55f.out
当前时间戳（秒）: 1747622494
Processing address: 63665be59e80a719572dced63c4bd47056d4af92
弱连通分量已写入文件: Randomadd_deposit/63665be59e80a719572dced63c4bd47056d4af92.out
当前时间戳（秒）: 1747622494
Processing address: 9b750e5c5ce17b4f7fab7230a3354d8181a5bb0c
弱连通分量已写入文件: Randomadd_deposit/9b750e5c5ce17b4f7fab7230a3354d8181a5bb0c.out
当前时间戳（秒）: 1747622494
Processing address: 289a889efeddcb1dd5dd9ac21e234f4027434895
弱连通分量已写入文件: Randomadd_deposit/289a889efeddcb1dd5dd9ac21e234f4027434895.out
当前时间戳（秒）: 1747622494
Processing address: be236a980ade9887986e2e6addcaff49db78fc67
org.janusgraph.core.JanusGraphException: Could not execute operation due to backend exception
	at org.janusgraph.diskstorage.util.BackendOperation.execute(BackendOperation.java:54)
	at org.janusgraph.diskstorage.BackendTransaction.executeRead(BackendTransaction.java:521)
	at org.janusgraph.diskstorage.BackendTransaction.edgeStoreMultiQuery(BackendTransaction.java:300)
	at org.janusgraph.graphdb.database.StandardJanusGraph.edgeMultiQuery(StandardJanusGraph.java:568)
	at org.janusgraph.graphdb.transaction.StandardJanusGraphTx.lambda$executeMultiQuery$4(StandardJanusGraphTx.java:1252)
	at org.janusgraph.graphdb.query.profile.QueryProfiler.profile(QueryProfiler.java:113)
	at org.janusgraph.graphdb.query.profile.QueryProfiler.profile(QueryProfiler.java:105)
	at org.janusgraph.graphdb.transaction.StandardJanusGraphTx.executeMultiQuery(StandardJanusGraphTx.java:1252)
	at org.janusgraph.graphdb.query.vertex.MultiVertexCentricQueryBuilder.execute(MultiVertexCentricQueryBuilder.java:121)
	at org.janusgraph.graphdb.query.vertex.MultiVertexCentricQueryBuilder.edges(MultiVertexCentricQueryBuilder.java:172)
	at org.janusgraph.graphdb.tinkerpop.optimize.step.fetcher.VertexStepBatchFetcher.makeQueryAndExecute(VertexStepBatchFetcher.java:39)
	at org.janusgraph.graphdb.tinkerpop.optimize.step.fetcher.MultiQueriableStepBatchFetcher.prefetchNextBatch(MultiQueriableStepBatchFetcher.java:112)
	at org.janusgraph.graphdb.tinkerpop.optimize.step.fetcher.MultiQueriableStepBatchFetcher.fetchData(MultiQueriableStepBatchFetcher.java:96)
	at org.janusgraph.graphdb.tinkerpop.optimize.step.JanusGraphVertexStep.flatMap(JanusGraphVertexStep.java:117)
	at org.apache.tinkerpop.gremlin.process.traversal.step.map.FlatMapStep.processNextStart(FlatMapStep.java:49)
	at org.apache.tinkerpop.gremlin.process.traversal.step.util.AbstractStep.next(AbstractStep.java:140)
	at org.apache.tinkerpop.gremlin.process.traversal.step.util.AbstractStep.next(AbstractStep.java:40)
	at org.apache.tinkerpop.gremlin.process.traversal.Traversal.fill(Traversal.java:184)
	at org.apache.tinkerpop.gremlin.process.traversal.Traversal.toList(Traversal.java:122)
	at entity.deposit.processInitAddress(deposit.java:131)
	at entity.deposit.processAddress(deposit.java:55)
	at entity.deposit.main(deposit.java:42)
	at org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:279)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.janusgraph.diskstorage.TemporaryBackendException: Could not successfully complete backend operation due to repeated temporary exceptions after PT8M20S
	at org.janusgraph.diskstorage.util.BackendOperation.executeDirect(BackendOperation.java:98)
	at org.janusgraph.diskstorage.util.BackendOperation.execute(BackendOperation.java:52)
	... 23 more
Caused by: org.janusgraph.diskstorage.TemporaryBackendException: Temporary failure in storage backend
	at org.janusgraph.diskstorage.hbase.HBaseKeyColumnValueStore.getHelper(HBaseKeyColumnValueStore.java:230)
	at org.janusgraph.diskstorage.hbase.HBaseKeyColumnValueStore.getSlice(HBaseKeyColumnValueStore.java:119)
	at org.janusgraph.diskstorage.keycolumnvalue.KCVSProxy.getSlice(KCVSProxy.java:87)
	at org.janusgraph.diskstorage.keycolumnvalue.cache.ExpirationKCVSCache.getSlice(ExpirationKCVSCache.java:122)
	at org.janusgraph.diskstorage.BackendTransaction$2.call(BackendTransaction.java:303)
	at org.janusgraph.diskstorage.BackendTransaction$2.call(BackendTransaction.java:300)
	at org.janusgraph.diskstorage.util.BackendOperation.executeDirect(BackendOperation.java:66)
	... 24 more
Caused by: org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=16, exceptions:
2025-05-19T02:42:35.587Z, RpcRetryingCaller{globalStartTime=2025-05-19T02:41:34.959Z, pause=100, maxAttempts=16}, org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=95,methodName=Get], waitTime=60084ms, rpcTimeout=60000ms
2025-05-19T02:43:35.715Z, RpcRetryingCaller{globalStartTime=2025-05-19T02:41:34.959Z, pause=100, maxAttempts=16}, org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=111,methodName=Get], waitTime=60004ms, rpcTimeout=60000ms
2025-05-19T02:44:35.935Z, RpcRetryingCaller{globalStartTime=2025-05-19T02:41:34.959Z, pause=100, maxAttempts=16}, org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=127,methodName=Get], waitTime=60006ms, rpcTimeout=60000ms
2025-05-19T02:45:36.254Z, RpcRetryingCaller{globalStartTime=2025-05-19T02:41:34.959Z, pause=100, maxAttempts=16}, org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=143,methodName=Get], waitTime=60005ms, rpcTimeout=60000ms
2025-05-19T02:46:36.775Z, RpcRetryingCaller{globalStartTime=2025-05-19T02:41:34.959Z, pause=100, maxAttempts=16}, org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=159,methodName=Get], waitTime=60009ms, rpcTimeout=60000ms
2025-05-19T02:47:37.794Z, RpcRetryingCaller{globalStartTime=2025-05-19T02:41:34.959Z, pause=100, maxAttempts=16}, org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=175,methodName=Get], waitTime=60004ms, rpcTimeout=60000ms
2025-05-19T02:48:39.893Z, RpcRetryingCaller{globalStartTime=2025-05-19T02:41:34.959Z, pause=100, maxAttempts=16}, org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=192,methodName=Get], waitTime=60005ms, rpcTimeout=60000ms
2025-05-19T02:49:43.936Z, RpcRetryingCaller{globalStartTime=2025-05-19T02:41:34.959Z, pause=100, maxAttempts=16}, org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=209,methodName=Get], waitTime=60011ms, rpcTimeout=60000ms
2025-05-19T02:50:54.045Z, RpcRetryingCaller{globalStartTime=2025-05-19T02:41:34.959Z, pause=100, maxAttempts=16}, org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=227,methodName=Get], waitTime=60010ms, rpcTimeout=60000ms
2025-05-19T02:52:04.056Z, RpcRetryingCaller{globalStartTime=2025-05-19T02:41:34.959Z, pause=100, maxAttempts=16}, org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=245,methodName=Get], waitTime=60002ms, rpcTimeout=60000ms
2025-05-19T02:53:14.155Z, RpcRetryingCaller{globalStartTime=2025-05-19T02:41:34.959Z, pause=100, maxAttempts=16}, org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=263,methodName=Get], waitTime=60006ms, rpcTimeout=60000ms
2025-05-19T02:54:24.246Z, RpcRetryingCaller{globalStartTime=2025-05-19T02:41:34.959Z, pause=100, maxAttempts=16}, org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=281,methodName=Get], waitTime=60002ms, rpcTimeout=60000ms
2025-05-19T02:55:44.285Z, RpcRetryingCaller{globalStartTime=2025-05-19T02:41:34.959Z, pause=100, maxAttempts=16}, org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=301,methodName=Get], waitTime=60003ms, rpcTimeout=60000ms
2025-05-19T02:57:04.495Z, RpcRetryingCaller{globalStartTime=2025-05-19T02:41:34.959Z, pause=100, maxAttempts=16}, org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=321,methodName=Get], waitTime=60009ms, rpcTimeout=60000ms
2025-05-19T02:58:24.694Z, RpcRetryingCaller{globalStartTime=2025-05-19T02:41:34.959Z, pause=100, maxAttempts=16}, org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=341,methodName=Get], waitTime=60006ms, rpcTimeout=60000ms
2025-05-19T02:59:44.815Z, RpcRetryingCaller{globalStartTime=2025-05-19T02:41:34.959Z, pause=100, maxAttempts=16}, org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=361,methodName=Get], waitTime=60000ms, rpcTimeout=60000ms

	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:141)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:390)
	at org.apache.hadoop.hbase.client.HTable.lambda$get$0(HTable.java:363)
	at org.apache.hadoop.hbase.trace.TraceUtil.trace(TraceUtil.java:216)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:363)
	at org.apache.hadoop.hbase.client.HTable.lambda$get$1(HTable.java:409)
	at org.apache.hadoop.hbase.trace.TraceUtil.trace(TraceUtil.java:216)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:407)
	at org.janusgraph.diskstorage.hbase.HBaseKeyColumnValueStore.getHelper(HBaseKeyColumnValueStore.java:198)
	... 30 more
Caused by: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call to address=node10:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=361,methodName=Get], waitTime=60000ms, rpcTimeout=60000ms
	at org.apache.hadoop.hbase.ipc.IPCUtil.wrapException(IPCUtil.java:222)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:392)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:92)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:426)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:421)
	at org.apache.hadoop.hbase.ipc.Call.setTimeout(Call.java:107)
	at org.apache.hadoop.hbase.ipc.RpcConnection$1.run(RpcConnection.java:134)
	at org.apache.hbase.thirdparty.io.netty.util.HashedWheelTimer$HashedWheelTimeout.run(HashedWheelTimer.java:715)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.ImmediateExecutor.execute(ImmediateExecutor.java:34)
	at org.apache.hbase.thirdparty.io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:703)
	at org.apache.hbase.thirdparty.io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:790)
	at org.apache.hbase.thirdparty.io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:503)
	... 1 more
Caused by: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call[id=361,methodName=Get], waitTime=60000ms, rpcTimeout=60000ms
	at org.apache.hadoop.hbase.ipc.RpcConnection$1.run(RpcConnection.java:135)
	... 6 more
弱连通分量已写入文件: Randomadd_deposit/be236a980ade9887986e2e6addcaff49db78fc67.out
当前时间戳（秒）: 1747623584
Processing address: bafd56d22ae053d9420b786c82144a926d5575fc
弱连通分量已写入文件: Randomadd_deposit/bafd56d22ae053d9420b786c82144a926d5575fc.out
当前时间戳（秒）: 1747623584
Processing address: 12aac61cb696e0196086c03596fe5bdc0cc2c70f
弱连通分量已写入文件: Randomadd_deposit/12aac61cb696e0196086c03596fe5bdc0cc2c70f.out
当前时间戳（秒）: 1747623584
Processing address: 1dccb6e514395148641fdcf86b55fd94626fec12
弱连通分量已写入文件: Randomadd_deposit/1dccb6e514395148641fdcf86b55fd94626fec12.out
当前时间戳（秒）: 1747623584
Processing address: e60af575cbdfa217009f1c02a77ff4d17d0b19a7
弱连通分量已写入文件: Randomadd_deposit/e60af575cbdfa217009f1c02a77ff4d17d0b19a7.out
当前时间戳（秒）: 1747623584
Processing address: 016d526082ed41f659a04fc5feb11516c940cdee
弱连通分量已写入文件: Randomadd_deposit/016d526082ed41f659a04fc5feb11516c940cdee.out
当前时间戳（秒）: 1747623584
[WARNING] thread Thread[Idle-Rpc-Conn-Sweeper-pool-0,5,entity.deposit] was interrupted but is still alive after waiting at least 14999msecs
[WARNING] thread Thread[Idle-Rpc-Conn-Sweeper-pool-0,5,entity.deposit] will linger despite being asked to die via interruption
[WARNING] thread Thread[RPCClient-NioEventLoopGroup-1-1,5,entity.deposit] will linger despite being asked to die via interruption
[WARNING] thread Thread[RpcClient-timer-pool-0,5,entity.deposit] will linger despite being asked to die via interruption
[WARNING] thread Thread[RPCClient-NioEventLoopGroup-1-2,5,entity.deposit] will linger despite being asked to die via interruption
[WARNING] thread Thread[RPCClient-NioEventLoopGroup-1-3,5,entity.deposit] will linger despite being asked to die via interruption
[WARNING] thread Thread[RPCClient-NioEventLoopGroup-1-4,5,entity.deposit] will linger despite being asked to die via interruption
[WARNING] thread Thread[RPCClient-NioEventLoopGroup-1-5,5,entity.deposit] will linger despite being asked to die via interruption
[WARNING] thread Thread[RPCClient-NioEventLoopGroup-1-6,5,entity.deposit] will linger despite being asked to die via interruption
[WARNING] thread Thread[RPCClient-NioEventLoopGroup-1-7,5,entity.deposit] will linger despite being asked to die via interruption
[WARNING] thread Thread[ForkJoinPool.commonPool-worker-0,5,entity.deposit] will linger despite being asked to die via interruption
[WARNING] thread Thread[ForkJoinPool.commonPool-worker-25,5,entity.deposit] will linger despite being asked to die via interruption
[WARNING] thread Thread[ForkJoinPool.commonPool-worker-18,5,entity.deposit] will linger despite being asked to die via interruption
[WARNING] thread Thread[RPCClient-NioEventLoopGroup-1-8,5,entity.deposit] will linger despite being asked to die via interruption
[WARNING] NOTE: 13 thread(s) did not finish despite being asked to via interruption. This is not a problem with exec:java, it is a problem with the running code. Although not serious, it should be remedied.
[WARNING] Couldn't destroy threadgroup org.codehaus.mojo.exec.ExecJavaMojo$IsolatedThreadGroup[name=entity.deposit,maxpri=10]
java.lang.IllegalThreadStateException
	at java.lang.ThreadGroup.destroy(ThreadGroup.java:778)
	at org.codehaus.mojo.exec.ExecJavaMojo.execute(ExecJavaMojo.java:319)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:207)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:307)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:193)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:106)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:863)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 18:38 min
[INFO] Finished at: 2025-05-19T11:00:00+08:00
[INFO] Final Memory: 63M/3506M
[INFO] ------------------------------------------------------------------------
